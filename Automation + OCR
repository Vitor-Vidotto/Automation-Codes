import pyautogui
import datetime
import time
import os
import pytesseract
import cv2
import numpy as np
import difflib
import re
from PIL import Image, ImageGrab

# pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"  # Windows

# Caminho da área de trabalho
desktop = os.path.join(os.path.expanduser("~"), "Desktop")
log_path = os.path.join(desktop, "log_cliques.txt")

def registrar_log(texto):
    with open(log_path, "a", encoding="utf-8") as f:
        f.write(f"[{datetime.datetime.now().strftime('%H:%M:%S')}] {texto}\n")

def esperar_ate_horario(hora, minuto):
    while True:
        agora = datetime.datetime.now()
        if agora.hour == hora and agora.minute == minuto:
            break
        time.sleep(1)

def extrair_textos_da_imagem(caminho_imagem):
    try:
        imagem = Image.open(caminho_imagem)
        texto = pytesseract.image_to_string(imagem)
        linhas = [linha.strip() for linha in texto.split('\n') if linha.strip()]
        return linhas
    except Exception as e:
        print(f"Erro ao extrair texto de {caminho_imagem}: {e}")
        registrar_log(f"Erro ao extrair texto de {caminho_imagem}: {e}")
        return []

def preprocessar_screenshot(image):
    img_np = np.array(image)
    img_gray = cv2.cvtColor(img_np, cv2.COLOR_BGR2GRAY)
    
    # Limiar adaptativo para destacar texto escuro
    img_bin = cv2.adaptiveThreshold(
        img_gray, 255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY_INV,
        15, 5
    )
    
    img_denoised = cv2.fastNlMeansDenoising(img_bin, h=15)
    
    return Image.fromarray(img_denoised)

def limpar_texto_ocr(texto):
    texto = texto.upper()

    # Remove prefixos indesejados, mas preserva 'FG'
    prefixos_indesejados = ['GM', 'BE ANS', 'GAP', 'KEYBOARDINTERRUPT', 'MIG', 'O GENE', 'IG SCORE SCORE', 'MIG 8']
    for p in prefixos_indesejados:
        if texto.startswith(p + ' '):
            texto = texto[len(p)+1:]
            break

    texto = texto.replace('¥', '-')
    texto = texto.replace('~', '-')
    texto = texto.replace('TIH00', '11H00')
    texto = texto.replace('HOO', 'H00')
    texto = texto.replace('HS59', 'H59')
    texto = texto.replace('HO0', 'H00')
    texto = texto.replace('—', '-')

    texto = re.sub(r'H[O0]{2}', 'H00', texto)
    texto = re.sub(r'[^A-Z0-9\s\-\:]', '', texto)
    texto = re.sub(r'\s+', ' ', texto).strip()

    return texto

def extrair_horarios(texto):
    padrao = re.compile(r'(\d{1,2}H\d{2})|(\d{1,2}:\d{2})')
    matches = padrao.findall(texto.upper())
    horarios = []
    for h1, h2 in matches:
        horarios.append(h1 if h1 else h2)
    return horarios

def horarios_batem(horarios_esperados, horarios_encontrados):
    def normalizar(h):
        return h.replace('H', ':')
    
    horarios_encontrados_norm = [normalizar(h) for h in horarios_encontrados]

    for h in horarios_esperados:
        h_norm = normalizar(h)
        if not any(
            abs(int(h_norm.split(':')[0]) - int(h2.split(':')[0])) <= 1 and
            abs(int(h_norm.split(':')[1]) - int(h2.split(':')[1])) <= 5
            for h2 in horarios_encontrados_norm
        ):
            return False
    return True

def clicar_por_texto_na_tela(texto_procurado, posicoes_ja_clicadas):
    screenshot = ImageGrab.grab()
    screenshot.save("debug_screenshot_original.png")

    imagem_processada = preprocessar_screenshot(screenshot)
    imagem_processada.save("debug_tela_processada.png")

    dados = pytesseract.image_to_data(
        imagem_processada,
        config='--psm 6',
        output_type=pytesseract.Output.DICT
    )

    linhas_detectadas = {}
    for i in range(len(dados['text'])):
        if int(dados['conf'][i]) < 30:
            continue

        linha_num = dados['line_num'][i]
        texto = dados['text'][i].strip()
        if not texto:
            continue

        if linha_num not in linhas_detectadas:
            linhas_detectadas[linha_num] = {
                'textos': [],
                'itens': 0
            }

        linhas_detectadas[linha_num]['textos'].append(texto)

        x = dados['left'][i]
        y = dados['top'][i]
        w = dados['width'][i]
        h = dados['height'][i]

        if 'x_min' not in linhas_detectadas[linha_num]:
            linhas_detectadas[linha_num]['x_min'] = x
            linhas_detectadas[linha_num]['x_max'] = x + w
            linhas_detectadas[linha_num]['y_min'] = y
            linhas_detectadas[linha_num]['y_max'] = y + h
        else:
            linhas_detectadas[linha_num]['x_min'] = min(linhas_detectadas[linha_num]['x_min'], x)
            linhas_detectadas[linha_num]['x_max'] = max(linhas_detectadas[linha_num]['x_max'], x + w)
            linhas_detectadas[linha_num]['y_min'] = min(linhas_detectadas[linha_num]['y_min'], y)
            linhas_detectadas[linha_num]['y_max'] = max(linhas_detectadas[linha_num]['y_max'], y + h)

        linhas_detectadas[linha_num]['itens'] += 1

    texto_procurado_limpo = limpar_texto_ocr(texto_procurado)

    melhor_score = 0
    melhor_match = None
    posicao_match = None

    for linha in linhas_detectadas.values():
        linha_texto = " ".join(linha['textos'])
        linha_texto = limpar_texto_ocr(linha_texto)

        score = difflib.SequenceMatcher(None, texto_procurado_limpo.lower(), linha_texto.lower()).ratio()

        if texto_procurado_limpo.lower() not in linha_texto.lower() and score < 0.75:
            continue

        horarios_esperados = extrair_horarios(texto_procurado_limpo)
        horarios_encontrados = extrair_horarios(linha_texto)

        if not horarios_batem(horarios_esperados, horarios_encontrados):
            continue

        # Calcula o clique no centro do retângulo da linha detectada
        x = (linha['x_min'] + linha['x_max']) // 2
        y = (linha['y_min'] + linha['y_max']) // 2

        for (px, py) in posicoes_ja_clicadas:
            if abs(px - x) < 40 and abs(py - y) < 20:
                break
        else:
            if score > melhor_score:
                melhor_score = score
                melhor_match = linha_texto
                posicao_match = (x, y)

    if posicao_match:
        pyautogui.click(posicao_match)
        posicoes_ja_clicadas.append(posicao_match)
        registrar_log(f"✔ Clique no texto: '{melhor_match}' ≈ '{texto_procurado}' em {posicao_match} (score={melhor_score:.2f})")
        print(f"✔ Clique no texto: '{melhor_match}' ≈ '{texto_procurado}' em {posicao_match}")
        time.sleep(1)
        return True
    else:
        registrar_log(f"❌ Nenhum texto correspondente a '{texto_procurado}' encontrado.")
        print(f"❌ Nenhum texto correspondente a '{texto_procurado}' encontrado.")
        return False

# Seletor de restaurante
opcoes = ['Fuji', 'Zendai', 'Columbia']
print("Selecione o restaurante para pesquisa:")
for i, nome in enumerate(opcoes, 1):
    print(f"{i}. {nome}")

while True:
    try:
        escolha = int(input("Digite o número correspondente: "))
        if 1 <= escolha <= len(opcoes):
            termo_de_busca = opcoes[escolha - 1]
            break
        else:
            print("Escolha inválida. Tente novamente.")
    except ValueError:
        print("Entrada inválida. Digite um número.")

registrar_log(f"Restaurante selecionado: {termo_de_busca}")
print(f"Restaurante escolhido: {termo_de_busca}")
'''
print("Esperando dar 17h...")


registrar_log("Aguardando 17h...")


esperar_ate_horario(17, 00)

print("É 17h! Executando ações...")

registrar_log("Executando ações às 17h.")




# Automação de busca (Ctrl+F)

pyautogui.press('f5')

registrar_log("Pressionado F5")


time.sleep(2)




pyautogui.hotkey('ctrl', 'f')

registrar_log("Pressionado Ctrl+F")

time.sleep(0.8)





pyautogui.write(termo_de_busca, interval=0.05)

registrar_log(f"Termo digitado: {termo_de_busca}")

time.sleep(0.5)




pyautogui.press('enter')

registrar_log("Pressionado Enter")


time.sleep(0.3)




# Apenas apaga o conteúdo da barra de busca (mantém aberta)


pyautogui.hotkey('ctrl', 'a')  # Seleciona tudo


time.sleep(0.1)


pyautogui.press('backspace')   # Apaga o texto


registrar_log("Texto da barra de busca apagado")
'''

time.sleep(2)

posicoes_ja_clicadas = []

print("Iniciando sequência de cliques por OCR em texto das imagens...")
registrar_log("Iniciando sequência de cliques por OCR em texto das imagens...")

prefixo_imagem = termo_de_busca.lower()
max_cliques = 10

for indice in range(1, max_cliques + 1):
    caminho_imagem = f"{prefixo_imagem}_click{indice}.png"
    linhas_texto = extrair_textos_da_imagem(caminho_imagem)

    if linhas_texto:
        for linha in linhas_texto:
            print(f"Procurando texto extraído: '{linha}'")
            registrar_log(f"Procurando texto extraído: '{linha}'")

            sucesso = clicar_por_texto_na_tela(linha, posicoes_ja_clicadas)
            time.sleep(0.5)
            if sucesso:
                break
    else:
        print(f"Não foi possível extrair texto de {caminho_imagem}")
        registrar_log(f"Não foi possível extrair texto de {caminho_imagem}")


for nome in ["verificar", "concluido"]:
    try:
        print(f"Procurando '{nome}.png'...")
        pyautogui.screenshot(f"debug_{nome}.png")  # Captura da tela para depuração
        pos = pyautogui.locateCenterOnScreen(f"{nome}.png", confidence=0.8)
        if pos:
            pyautogui.click(pos)
            registrar_log(f"Clique na imagem: {nome}.png")
            print(f"✔ Clique realizado em '{nome}.png'")
            time.sleep(0.5)
        else:
            print(f"❌ Imagem '{nome}.png' não encontrada.")
            registrar_log(f"Imagem '{nome}.png' não encontrada.")
    except Exception as e:
        print(f"Erro ao buscar imagem {nome}.png: {e}")
        registrar_log(f"Erro ao buscar imagem {nome}.png: {e}")
